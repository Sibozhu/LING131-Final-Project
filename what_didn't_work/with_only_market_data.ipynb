{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "#Module installation\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "# from kaggle.competitions import twosigmanews #Comment out here because this dataset is exclusive in Kaggle kernel\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from datetime import datetime, date\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#Comment out this chunk because the whole dataset is exclusive in Kaggle kernel\n",
    "\n",
    "#Collecting Dataset\n",
    "# from kaggle.competitions import twosigmanews\n",
    "# env = twosigmanews.make_env()\n",
    "# print('Finished collecting data!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "4ff149df14250f7e68cbde3e3c9f44fdd6956a0f"
   },
   "outputs": [],
   "source": [
    "#Sorting and storing Stock data and news data respectively\n",
    "# (market_train_df, news_train_df) = env.get_training_data() #This is for Kaggle kernel version only\n",
    "market_train_df = pd.read_csv(\"marketdata_sample.csv\")\n",
    "news_train_df = pd.read_csv(\"news_sample.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>sourceTimestamp</th>\n",
       "      <th>firstCreated</th>\n",
       "      <th>sourceId</th>\n",
       "      <th>headline</th>\n",
       "      <th>urgency</th>\n",
       "      <th>takeSequence</th>\n",
       "      <th>provider</th>\n",
       "      <th>subjects</th>\n",
       "      <th>audiences</th>\n",
       "      <th>...</th>\n",
       "      <th>noveltyCount12H</th>\n",
       "      <th>noveltyCount24H</th>\n",
       "      <th>noveltyCount3D</th>\n",
       "      <th>noveltyCount5D</th>\n",
       "      <th>noveltyCount7D</th>\n",
       "      <th>volumeCounts12H</th>\n",
       "      <th>volumeCounts24H</th>\n",
       "      <th>volumeCounts3D</th>\n",
       "      <th>volumeCounts5D</th>\n",
       "      <th>volumeCounts7D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-01-01 04:29:32+00:00</td>\n",
       "      <td>2007-01-01 04:29:32+00:00</td>\n",
       "      <td>2007-01-01 04:29:32+00:00</td>\n",
       "      <td>e58c6279551b85cf</td>\n",
       "      <td>China's Daqing pumps 43.41 mln tonnes of oil i...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>RTRS</td>\n",
       "      <td>{'CRU', 'CN', 'RTRS', 'ENR', 'LEN', 'EMRG', 'N...</td>\n",
       "      <td>{'O', 'Z', 'OIL'}</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-01 07:03:35+00:00</td>\n",
       "      <td>2007-01-01 07:03:34+00:00</td>\n",
       "      <td>2007-01-01 07:03:34+00:00</td>\n",
       "      <td>5a31c4327427f63f</td>\n",
       "      <td>FEATURE-In kidnapping, finesse works best</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>RTRS</td>\n",
       "      <td>{'BD', 'INS', 'LATAM', 'CA', 'US', 'MX', 'IL',...</td>\n",
       "      <td>{'PGE', 'PCU', 'PCO', 'DNP', 'MD', 'E', 'G', '...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-01-01 11:29:56+00:00</td>\n",
       "      <td>2007-01-01 11:29:56+00:00</td>\n",
       "      <td>2007-01-01 11:29:56+00:00</td>\n",
       "      <td>1cefd27a40fabdfe</td>\n",
       "      <td>PRESS DIGEST - Wall Street Journal - Jan 1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>RTRS</td>\n",
       "      <td>{'IQ', 'RO', 'US', 'ID', 'RET', 'RTRS', 'ENR',...</td>\n",
       "      <td>{'M', 'PMF', 'DNP', 'PTD', 'T', 'E', 'D', 'PSC...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-01 12:08:37+00:00</td>\n",
       "      <td>2007-01-01 12:08:37+00:00</td>\n",
       "      <td>2007-01-01 12:08:37+00:00</td>\n",
       "      <td>23768af19dc69992</td>\n",
       "      <td>PRESS DIGEST - New York Times - Jan 1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>RTRS</td>\n",
       "      <td>{'PUB', 'BUS', 'INS', 'CA', 'ENT', 'US', 'FIN'...</td>\n",
       "      <td>{'M', 'PMF', 'DNP', 'PTD', 'T', 'E', 'D', 'PSC...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-01 12:08:37+00:00</td>\n",
       "      <td>2007-01-01 12:08:37+00:00</td>\n",
       "      <td>2007-01-01 12:08:37+00:00</td>\n",
       "      <td>23768af19dc69992</td>\n",
       "      <td>PRESS DIGEST - New York Times - Jan 1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>RTRS</td>\n",
       "      <td>{'PUB', 'BUS', 'INS', 'CA', 'ENT', 'US', 'FIN'...</td>\n",
       "      <td>{'M', 'PMF', 'DNP', 'PTD', 'T', 'E', 'D', 'PSC...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time            sourceTimestamp  \\\n",
       "0  2007-01-01 04:29:32+00:00  2007-01-01 04:29:32+00:00   \n",
       "1  2007-01-01 07:03:35+00:00  2007-01-01 07:03:34+00:00   \n",
       "2  2007-01-01 11:29:56+00:00  2007-01-01 11:29:56+00:00   \n",
       "3  2007-01-01 12:08:37+00:00  2007-01-01 12:08:37+00:00   \n",
       "4  2007-01-01 12:08:37+00:00  2007-01-01 12:08:37+00:00   \n",
       "\n",
       "                firstCreated          sourceId  \\\n",
       "0  2007-01-01 04:29:32+00:00  e58c6279551b85cf   \n",
       "1  2007-01-01 07:03:34+00:00  5a31c4327427f63f   \n",
       "2  2007-01-01 11:29:56+00:00  1cefd27a40fabdfe   \n",
       "3  2007-01-01 12:08:37+00:00  23768af19dc69992   \n",
       "4  2007-01-01 12:08:37+00:00  23768af19dc69992   \n",
       "\n",
       "                                            headline  urgency  takeSequence  \\\n",
       "0  China's Daqing pumps 43.41 mln tonnes of oil i...        3             1   \n",
       "1          FEATURE-In kidnapping, finesse works best        3             1   \n",
       "2         PRESS DIGEST - Wall Street Journal - Jan 1        3             1   \n",
       "3              PRESS DIGEST - New York Times - Jan 1        3             1   \n",
       "4              PRESS DIGEST - New York Times - Jan 1        3             1   \n",
       "\n",
       "  provider                                           subjects  \\\n",
       "0     RTRS  {'CRU', 'CN', 'RTRS', 'ENR', 'LEN', 'EMRG', 'N...   \n",
       "1     RTRS  {'BD', 'INS', 'LATAM', 'CA', 'US', 'MX', 'IL',...   \n",
       "2     RTRS  {'IQ', 'RO', 'US', 'ID', 'RET', 'RTRS', 'ENR',...   \n",
       "3     RTRS  {'PUB', 'BUS', 'INS', 'CA', 'ENT', 'US', 'FIN'...   \n",
       "4     RTRS  {'PUB', 'BUS', 'INS', 'CA', 'ENT', 'US', 'FIN'...   \n",
       "\n",
       "                                           audiences       ...        \\\n",
       "0                                  {'O', 'Z', 'OIL'}       ...         \n",
       "1  {'PGE', 'PCU', 'PCO', 'DNP', 'MD', 'E', 'G', '...       ...         \n",
       "2  {'M', 'PMF', 'DNP', 'PTD', 'T', 'E', 'D', 'PSC...       ...         \n",
       "3  {'M', 'PMF', 'DNP', 'PTD', 'T', 'E', 'D', 'PSC...       ...         \n",
       "4  {'M', 'PMF', 'DNP', 'PTD', 'T', 'E', 'D', 'PSC...       ...         \n",
       "\n",
       "   noveltyCount12H  noveltyCount24H noveltyCount3D  noveltyCount5D  \\\n",
       "0                0                0              0               0   \n",
       "1                1                1              1               1   \n",
       "2                0                0              0               0   \n",
       "3                0                0              0               0   \n",
       "4                0                0              0               0   \n",
       "\n",
       "   noveltyCount7D  volumeCounts12H volumeCounts24H volumeCounts3D  \\\n",
       "0               0                0               0              3   \n",
       "1               1                1               1              3   \n",
       "2               0                0               0              5   \n",
       "3               0                0               0              5   \n",
       "4               0                0               0              0   \n",
       "\n",
       "   volumeCounts5D  volumeCounts7D  \n",
       "0               6               7  \n",
       "1               3               3  \n",
       "2              11              17  \n",
       "3              13              15  \n",
       "4               0               0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "404f9729417c7d54ea31fc693e8a9d6907be1453"
   },
   "outputs": [],
   "source": [
    "#Comment out this chunk due to the difference reading dataset from Kaggle environment and reading directly from .csv file\n",
    "\n",
    "#Reformat \"time\" to date\n",
    "# market_train_df['time'] = market_train_df['time'].dt.date\n",
    "#Save data only for 2010\n",
    "# market_train_df = market_train_df.loc[market_train_df['time']>=date(2010, 1, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "302f2f9696d7d7c6c4e0e4efe136fa4c7500c532"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>assetCode</th>\n",
       "      <th>assetName</th>\n",
       "      <th>universe</th>\n",
       "      <th>volume</th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>returnsClosePrevRaw1</th>\n",
       "      <th>returnsOpenPrevRaw1</th>\n",
       "      <th>returnsClosePrevMktres1</th>\n",
       "      <th>returnsOpenPrevMktres1</th>\n",
       "      <th>returnsClosePrevRaw10</th>\n",
       "      <th>returnsOpenPrevRaw10</th>\n",
       "      <th>returnsClosePrevMktres10</th>\n",
       "      <th>returnsOpenPrevMktres10</th>\n",
       "      <th>returnsOpenNextMktres10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-02-01 22:00:00+00:00</td>\n",
       "      <td>A.N</td>\n",
       "      <td>Agilent Technologies Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2606900.0</td>\n",
       "      <td>32.19</td>\n",
       "      <td>32.17</td>\n",
       "      <td>0.005938</td>\n",
       "      <td>0.005312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001860</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-02-01 22:00:00+00:00</td>\n",
       "      <td>AAI.N</td>\n",
       "      <td>AirTran Holdings Inc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2051600.0</td>\n",
       "      <td>11.12</td>\n",
       "      <td>11.08</td>\n",
       "      <td>0.004517</td>\n",
       "      <td>-0.007168</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.078708</td>\n",
       "      <td>-0.088066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-02-01 22:00:00+00:00</td>\n",
       "      <td>AAP.N</td>\n",
       "      <td>Advance Auto Parts Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1164800.0</td>\n",
       "      <td>37.51</td>\n",
       "      <td>37.99</td>\n",
       "      <td>-0.011594</td>\n",
       "      <td>0.025648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014332</td>\n",
       "      <td>0.045405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-02-01 22:00:00+00:00</td>\n",
       "      <td>AAPL.O</td>\n",
       "      <td>Apple Inc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23747329.0</td>\n",
       "      <td>84.74</td>\n",
       "      <td>86.23</td>\n",
       "      <td>-0.011548</td>\n",
       "      <td>0.016324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.048613</td>\n",
       "      <td>-0.037182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-02-01 22:00:00+00:00</td>\n",
       "      <td>ABB.N</td>\n",
       "      <td>ABB Ltd</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1208600.0</td>\n",
       "      <td>18.02</td>\n",
       "      <td>18.01</td>\n",
       "      <td>0.011791</td>\n",
       "      <td>0.025043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012929</td>\n",
       "      <td>0.020397</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.017994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time assetCode                 assetName  universe  \\\n",
       "0  2007-02-01 22:00:00+00:00       A.N  Agilent Technologies Inc       1.0   \n",
       "1  2007-02-01 22:00:00+00:00     AAI.N      AirTran Holdings Inc       0.0   \n",
       "2  2007-02-01 22:00:00+00:00     AAP.N    Advance Auto Parts Inc       1.0   \n",
       "3  2007-02-01 22:00:00+00:00    AAPL.O                 Apple Inc       1.0   \n",
       "4  2007-02-01 22:00:00+00:00     ABB.N                   ABB Ltd       1.0   \n",
       "\n",
       "       volume  close   open  returnsClosePrevRaw1  returnsOpenPrevRaw1  \\\n",
       "0   2606900.0  32.19  32.17              0.005938             0.005312   \n",
       "1   2051600.0  11.12  11.08              0.004517            -0.007168   \n",
       "2   1164800.0  37.51  37.99             -0.011594             0.025648   \n",
       "3  23747329.0  84.74  86.23             -0.011548             0.016324   \n",
       "4   1208600.0  18.02  18.01              0.011791             0.025043   \n",
       "\n",
       "   returnsClosePrevMktres1  returnsOpenPrevMktres1  returnsClosePrevRaw10  \\\n",
       "0                      NaN                     NaN              -0.001860   \n",
       "1                      NaN                     NaN              -0.078708   \n",
       "2                      NaN                     NaN               0.014332   \n",
       "3                      NaN                     NaN              -0.048613   \n",
       "4                      NaN                     NaN               0.012929   \n",
       "\n",
       "   returnsOpenPrevRaw10  returnsClosePrevMktres10  returnsOpenPrevMktres10  \\\n",
       "0              0.000622                       NaN                      NaN   \n",
       "1             -0.088066                       NaN                      NaN   \n",
       "2              0.045405                       NaN                      NaN   \n",
       "3             -0.037182                       NaN                      NaN   \n",
       "4              0.020397                       NaN                      NaN   \n",
       "\n",
       "   returnsOpenNextMktres10  \n",
       "0                 0.034672  \n",
       "1                 0.027803  \n",
       "2                 0.024433  \n",
       "3                -0.007425  \n",
       "4                -0.017994  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "06db696df59db8381b4518124a95ddf6c3a18941"
   },
   "outputs": [],
   "source": [
    "#Importing modules for parallel work\n",
    "from multiprocessing import Pool\n",
    "\n",
    "#create_lag (average maximum minimum standard deviation creation method for moving average)\n",
    "#Default values are included in method definition brackets\n",
    "\n",
    "def create_lag(df_code,n_lag=[3,7,14,],shift_size=1):\n",
    "\n",
    "    #Put df_code's asset code in code without duplication\n",
    "    code = df_code['assetCode'].unique()\n",
    "    \n",
    "    #From return_features (revenue function) to col variable\n",
    "    for col in return_features:\n",
    "        #Loop n_lag to window variable\n",
    "        for window in n_lag:\n",
    "            #The value of the window variable is shifted from the present by the previous moving average value\n",
    "            rolled = df_code[col].shift(shift_size).rolling(window=window)\n",
    "            #Averages of moving average\n",
    "            lag_mean = rolled.mean()\n",
    "            #Maximal\n",
    "            lag_max = rolled.max()\n",
    "            #Minimal\n",
    "            lag_min = rolled.min()\n",
    "            #Standard Deviation\n",
    "            lag_std = rolled.std()\n",
    "            #Storing in df_code by the column name of col's value of _lag_window's value _mean\n",
    "            df_code['%s_lag_%s_mean'%(col,window)] = lag_mean\n",
    "            df_code['%s_lag_%s_max'%(col,window)] = lag_max\n",
    "            df_code['%s_lag_%s_min'%(col,window)] = lag_min\n",
    "            #Leaving STD out for now\n",
    "#             df_code['%s_lag_%s_std'%(col,window)] = lag_std\n",
    "   \n",
    "    #If there is a null value in df_code, return it with -1\n",
    "    return df_code.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_lag_features\n",
    "def generate_lag_features(df,n_lag = [3,7,14]):\n",
    "    #Put all the stock price data in features (feature variable)\n",
    "    features = ['time', 'assetCode', 'assetName', 'volume', 'close', 'open',\n",
    "       'returnsClosePrevRaw1', 'returnsOpenPrevRaw1',\n",
    "       'returnsClosePrevMktres1', 'returnsOpenPrevMktres1',\n",
    "       'returnsClosePrevRaw10', 'returnsOpenPrevRaw10',\n",
    "       'returnsClosePrevMktres10', 'returnsOpenPrevMktres10',\n",
    "       'returnsOpenNextMktres10', 'universe']\n",
    "    #Duplicate deletion of assetCode (stock code)\n",
    "    assetCodes = df['assetCode'].unique()\n",
    "    print(assetCodes)\n",
    "    #Initiating all_df\n",
    "    all_df = []\n",
    "    #Stored in df_codes as aggregated by assetCode (SQL group by)\n",
    "    df_codes = df.groupby('assetCode')\n",
    "    df_codes = [df_code[1][['time','assetCode']+return_features] for df_code in df_codes]\n",
    "    #showing the total length of df_codes\n",
    "    print('total %s df'%len(df_codes))\n",
    "    \n",
    "    #Using 4 CPUs\n",
    "    pool = Pool(4)\n",
    "    #The result of substituting the argument of df_codes into the create_lag method and storing it in all_df\n",
    "    all_df = pool.map(create_lag, df_codes)\n",
    "    \n",
    "    #Tie all_df to new_df\n",
    "    new_df = pd.concat(all_df)\n",
    "    #delete line with return_features empty value\n",
    "    new_df.drop(return_features,axis=1,inplace=True)\n",
    "    #Parallel processing end\n",
    "    pool.close()\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "34630df14f3e514becabd95623fa2456c48f7759"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A.N' 'AAI.N' 'AAP.N' 'AAPL.O' 'ABB.N' 'ABC.N' 'ABD.N' 'ABM.N' 'ABT.N'\n",
      " 'ABV.N' 'ABY.N' 'ACF.N' 'ACH.N' 'ACL.N' 'ACS.N' 'ACTS.O' 'ACXM.O' 'AD.N'\n",
      " 'ADBE.O' 'ADCT.O' 'ADI.N' 'ADM.N' 'ADP.N' 'ADS.N' 'ADSK.O' 'ADTN.O'\n",
      " 'AEA.N' 'AEE.N' 'AEG.N' 'AEIS.O' 'AEL.N' 'AEOS.O' 'AEP.N' 'AER.N' 'AES.N'\n",
      " 'AET.N' 'AF.N' 'AFFX.O' 'AFG.N' 'AFL.N' 'AFR.N' 'AG.N' 'AGE.N' 'AGN.N'\n",
      " 'AGU.N' 'AH.N' 'AHG.N' 'AHL.N' 'AHS.N' 'AHT.N' 'AIN.N' 'AINV.O' 'AIR.N'\n",
      " 'AIT.N' 'AIV.N' 'AIZ.N' 'AJG.N' 'AKAM.O' 'AKR.N' 'AKS.N' 'ALB.N' 'ALD.N'\n",
      " 'ALGN.O' 'ALK.N' 'ALL.N' 'ALNY.O' 'ALO.N' 'ALTR.O' 'ALU.N' 'ALV.N'\n",
      " 'ALXN.O' 'AMAT.O' 'AMD.N' 'AME.N' 'AMED.O' 'AMG.N' 'AMGN.O' 'AMKR.O'\n",
      " 'AMLN.O' 'AMMD.O' 'AMP.N' 'AMT.N' 'AMTD.O' 'AMX.N' 'AMZN.O' 'AN.N'\n",
      " 'ANDE.O' 'ANDW.O' 'ANF.N' 'ANR.N' 'AOC.N' 'AOS.N' 'APA.N' 'APC.N' 'APD.N'\n",
      " 'APH.N' 'APKT.O' 'APOL.O' 'APPB.O' 'AQNT.O']\n",
      "total 100 df\n"
     ]
    }
   ],
   "source": [
    "#Setting return_features (revenue function) (eventually not just the closing price)\n",
    "return_features = ['returnsClosePrevMktres10','returnsClosePrevRaw10','open','close']\n",
    "#Setting the number of days for moving average\n",
    "n_lag = [3,7,14]\n",
    "#Time series feature extraction method to stock price training data, 3, 7, 14 moving average averaged\n",
    "new_df = generate_lag_features(market_train_df,n_lag=n_lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b3a49a3f3a02de7bbe7c65197011f237129bf1d9",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b0796f6ca4020110312b828d21cef80bf79269a4"
   },
   "outputs": [],
   "source": [
    "#The moving average data is added to the stock price training data by time and the outer join by the assetCode column\n",
    "market_train_df = pd.merge(market_train_df,new_df,how='left',on=['time','assetCode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "92f6558993f3a3b932a7bfaa94ee2e7a575d366a"
   },
   "outputs": [],
   "source": [
    "#Check if moving average is properly added\n",
    "print(market_train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "302a5d2900f6c1b5a64d957a736247f068b6c426"
   },
   "outputs": [],
   "source": [
    "market_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a65eaf741fc937ea1828368aa0d7ba56a82dd54b"
   },
   "outputs": [],
   "source": [
    "#mis_impute method (null value substitution)\n",
    "def mis_impute(data):\n",
    "    #Pull columns one by one\n",
    "    for i in data.columns:\n",
    "        #If the type is a string, replace the null value with other\n",
    "        if data[i].dtype == \"object\":\n",
    "            data[i] = data[i].fillna(\"other\")\n",
    "        #If the type is numeric, empty value is replaced with average value\n",
    "        elif (data[i].dtype == \"int64\" or data[i].dtype == \"float64\"):\n",
    "            data[i] = data[i].fillna(data[i].mean())\n",
    "        else:\n",
    "            pass\n",
    "    return data\n",
    "#Replace stock price training data with reshaped data\n",
    "market_train_df = mis_impute(market_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6ed6313b2510f55dd160cf56461fa9f76f5d8aed"
   },
   "outputs": [],
   "source": [
    "#reshape data_prep\n",
    "def data_prep(market_train):\n",
    "    #While deletion of stock code duplication, pull one by one column while adding line number\n",
    "    lbl = {k: v for v, k in enumerate(market_train['assetCode'].unique())}\n",
    "    #Processing the stock code as above (probably adding line number to assetCodeT and putting it there)\n",
    "    market_train['assetCodeT'] = market_train['assetCode'].map(lbl)\n",
    "    #Delete null value row\n",
    "    market_train = market_train.dropna(axis=0)\n",
    "    return market_train\n",
    "#Execute the above method\n",
    "market_train_df = data_prep(market_train_df)\n",
    "#shape indicates how many rows of data there are vertically and horizontally\n",
    "print(market_train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7b125f168143a2c1c963dc49b9315d1ecf129981"
   },
   "outputs": [],
   "source": [
    "#You can see that assetCodeT is falling apart\n",
    "market_train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "28a319be7fd82500778ef562f5c851ea96c2e4cd"
   },
   "outputs": [],
   "source": [
    "#Import modules to change data to numbers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#Only those that stock price stagnated or increased after ten days are thrown into the up variable\n",
    "up = market_train_df['returnsOpenNextMktres10'] >= 0\n",
    "\n",
    "#The value of universe (this can not be used as training data except 1) is thrown into the universe variable\n",
    "universe = market_train_df['universe'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "013965849984e1637f397e62b166c69142e1bbc6"
   },
   "outputs": [],
   "source": [
    "universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2c0d9a765484efce4f9e8c68659ef4d9f9650eb9"
   },
   "outputs": [],
   "source": [
    "#Dump into time variable\n",
    "d = market_train_df['time']\n",
    "#Fianl selection of training data\n",
    "#Pull out columns one by one\n",
    "#The following columns are designed to be excluded\n",
    "fcol = [c for c in market_train_df if c not in ['assetCode', 'assetCodes', 'assetCodesLen', 'assetName', 'audiences', \n",
    "                                             'firstCreated', 'headline', 'headlineTag', 'marketCommentary', 'time_x','provider', \n",
    "                                             'returnsOpenNextMktres10', 'sourceId', 'subjects', 'time', 'universe','sourceTimestamp']]\n",
    "fcol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7f4972b56f864940ecb0551dc855a8bac3913302"
   },
   "outputs": [],
   "source": [
    "#Pull down the value of the column finally selected above\n",
    "X = market_train_df[fcol].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9e371d4c812e5b3ef3c0d9df76723bec12e598ad"
   },
   "outputs": [],
   "source": [
    "#Set the value of TrueFalse of returnsOpenNextMktres10\n",
    "up = up.values\n",
    "up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "248311406fdfeb12c1921939cd3a2ea9ce02d8d4"
   },
   "outputs": [],
   "source": [
    "#r is not TrueFalse but throws the actual value\n",
    "r = market_train_df.returnsOpenNextMktres10.values\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6ad7076989b79b3ae6caaa6791b61fad173be09c"
   },
   "outputs": [],
   "source": [
    "# Setting X value's range\n",
    "#Minimum value for each column\n",
    "mins = np.min(X, axis=0)\n",
    "mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6dc7fdac5e1dcb93971084748bbf9030ba3156c3"
   },
   "outputs": [],
   "source": [
    "#Maximum value of each column\n",
    "maxs = np.max(X, axis=0)\n",
    "maxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cf2a6abc91d2655da95cdc71ec6a3def86238f14"
   },
   "outputs": [],
   "source": [
    "#Calculating the range between maximal and minimal\n",
    "rng = maxs - mins\n",
    "rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b19d29e62af5a9640026b204a27171fd82c6956a"
   },
   "outputs": [],
   "source": [
    "#Insert X in how far it is from the lowest value\n",
    "X = 1 - ((maxs - X) / rng)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6f5aff4e150761217548d9486a0568bdc3e556f1"
   },
   "outputs": [],
   "source": [
    "#Validate consistency\n",
    "assert X.shape[0] == up.shape[0] == r.shape[0]\n",
    "print(X.shape[0])\n",
    "print(up.shape[0])\n",
    "print(r.shape[0])\n",
    "#Confirm that the number of each list matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f850a0d1eaa095bd7b4eb3ae8f4633f6f0c02349"
   },
   "outputs": [],
   "source": [
    "#Inserting Xgboost here\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "483a754de67e23475d4c4f1d4ffc87eaf4d4fe79"
   },
   "outputs": [],
   "source": [
    "#Work to separate training data and test data\n",
    "X_train, X_test, up_train, up_test, r_train, r_test,u_train,u_test,d_train,d_test = \\\n",
    "model_selection.train_test_split(X, up, r,universe,d, test_size=0.25, random_state=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3f3cafc884990478034d46db46ce5aa8e24f1d89"
   },
   "outputs": [],
   "source": [
    "#Setting up the LightGBM training data\n",
    "train_data = lgb.Dataset(X, label=up.astype(int))\n",
    "#Setting test data of LightGBM\n",
    "test_data = lgb.Dataset(X_test, label=up_test.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "136f82932cda9d2508a6f15eefdc80f80d1f4039"
   },
   "outputs": [],
   "source": [
    "# Setting LightGBM parameters \n",
    "x_1 = [0.19000424246380565, 2452, 212, 328, 202]\n",
    "x_2 = [0.19016805202090095, 2583, 213, 312, 220]\n",
    "print(up_train)\n",
    "\n",
    "def exp_loss(p,y):\n",
    "    y = y.get_label()\n",
    "    grad = -y*(1.0-1.0/(1.0+np.exp(-y*p)))\n",
    "    hess = -(np.exp(y*p)*(y*p-1)-1)/((np.exp(y*p)+1)**2)\n",
    "    \n",
    "    return grad,hess\n",
    "###########################################\n",
    "#Parameter tuning of actual machine learning\n",
    "params_1 = {\n",
    "        #settings for increasing accuracy\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "#         'objective': 'regression',\n",
    "        #Learning degree (smaller value is better)\n",
    "        'learning_rate': x_1[0],\n",
    "        #Number of leaves (The larger the value, the better, but it is sometimes clogged if it is too big)\n",
    "        'num_leaves': x_1[1],\n",
    "        #Minimum number of leaves\n",
    "        'min_data_in_leaf': x_1[2],\n",
    "#         'num_iteration': x_1[3],\n",
    "        #Number of iterations (larger value is better)\n",
    "        'num_iteration': 239,\n",
    "        #Increasing this value will increase accuracy but will be heavier. \n",
    "        'max_bin': x_1[4],\n",
    "        #Setting of redundancy warning (0 is error output, 1 is log output, 2 is debugging)\n",
    "        'verbose': 1\n",
    "    }\n",
    "#The second item is set to another value by the same method\n",
    "params_2 = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "#         'objective': 'regression',\n",
    "        'learning_rate': x_2[0],\n",
    "        'num_leaves': x_2[1],\n",
    "        'min_data_in_leaf': x_2[2],\n",
    "#         'num_iteration': x_2[3],\n",
    "        'num_iteration': 172,\n",
    "        'max_bin': x_2[4],\n",
    "        'verbose': 1\n",
    "    }\n",
    "\n",
    "gbm_1 = lgb.train(params_1,\n",
    "        train_data,\n",
    "#It's not a big deal, but num_boost_round should be at least 200 and choose the fewest number of error rates for the test data.\n",
    "#As for num_boost_round, there are some parts that are not convincing, so we will consider it later.\n",
    "#After several tries, 133 times seems to be good.\n",
    "        #Probably setting number of round of learning\n",
    "        num_boost_round=133,\n",
    "        #The location of the data for answers?\n",
    "        valid_sets=test_data,\n",
    "        #Minimal learning round\n",
    "        early_stopping_rounds=5,\n",
    "#         fobj=exp_loss,\n",
    "        )\n",
    "#Same thing below\n",
    "gbm_2 = lgb.train(params_2,\n",
    "        train_data,\n",
    "        num_boost_round=133,\n",
    "        valid_sets=test_data,\n",
    "        early_stopping_rounds=5,\n",
    "#         fobj=exp_loss,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6c66369ca2a32b9a86a6aaf98adbaf288bb91b49"
   },
   "outputs": [],
   "source": [
    "#We average out the 1st data and the 2nd data\n",
    "confidence_test = (gbm_1.predict(X_test) + gbm_2.predict(X_test))/2\n",
    "confidence_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "55589ca05e8c982439efe1ad9cf19fbf6ceefd4d"
   },
   "outputs": [],
   "source": [
    "#Calculate the percentage of the predicted value\n",
    "confidence_test = (confidence_test-confidence_test.min())/(confidence_test.max()-confidence_test.min())\n",
    "confidence_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e5e6db1e2e7963aef26c4ffdc1832f4f0f6f9c0b"
   },
   "outputs": [],
   "source": [
    "confidence_test = confidence_test*2-1\n",
    "print(max(confidence_test),min(confidence_test))\n",
    "confidence_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3dbef3e10363bc9df63292b146cba44311ba3b17"
   },
   "outputs": [],
   "source": [
    "# Calculating the actual metrics used to calculate the final score\n",
    "r_test = r_test.clip(-1,1) \n",
    "x_t_i = confidence_test * r_test * u_test\n",
    "#Create a data frame with only dates and score values\n",
    "data = {'day' : d_test, 'x_t_i' : x_t_i}\n",
    "df = pd.DataFrame(data)\n",
    "#We reorganize multidimensional arrays into one dimension by group by group (aggregate) by date\n",
    "x_t = df.groupby('day').sum().values.flatten()\n",
    "#Mean of score\n",
    "mean = np.mean(x_t)\n",
    "#Standard deviation of score\n",
    "std = np.std(x_t)\n",
    "#Reciprocal of coefficient of variation\n",
    "score_test = mean / std\n",
    "print(score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "65da0a50ea0df84261ff437dbf934a31242b2ccd"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "del X_train,X_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3351f7ef017a67f4ea8563be79230f5bd659d965"
   },
   "outputs": [],
   "source": [
    "#prediction\n",
    "days = env.get_prediction_days()\n",
    "n_days = 0\n",
    "prep_time = 0\n",
    "prediction_time = 0\n",
    "packaging_time = 0\n",
    "total_market_obs_df = []\n",
    "for (market_obs_df, news_obs_df, predictions_template_df) in days:\n",
    "    n_days +=1\n",
    "    if (n_days%50==0):\n",
    "        print(n_days,end=' ')\n",
    "    t = time.time()\n",
    "    market_obs_df['time'] = market_obs_df['time'].dt.date\n",
    "    \n",
    "    return_features = ['returnsClosePrevMktres10','returnsClosePrevRaw10','open','close']\n",
    "    total_market_obs_df.append(market_obs_df)\n",
    "    if len(total_market_obs_df)==1:\n",
    "        history_df = total_market_obs_df[0]\n",
    "    else:\n",
    "        history_df = pd.concat(total_market_obs_df[-(np.max(n_lag)+1):])\n",
    "    print(history_df)\n",
    "    \n",
    "    new_df = generate_lag_features(history_df,n_lag=[3,7,14])\n",
    "    market_obs_df = pd.merge(market_obs_df,new_df,how='left',on=['time','assetCode'])\n",
    "    \n",
    "#     return_features = ['open']\n",
    "#     new_df = generate_lag_features(market_obs_df,n_lag=[3,7,14])\n",
    "#     market_obs_df = pd.merge(market_obs_df,new_df,how='left',on=['time','assetCode'])\n",
    "    \n",
    "    market_obs_df = mis_impute(market_obs_df)\n",
    "    \n",
    "    market_obs_df = data_prep(market_obs_df)\n",
    "    \n",
    "#     market_obs_df = market_obs_df[market_obs_df.assetCode.isin(predictions_template_df.assetCode)]\n",
    "    \n",
    "    X_live = market_obs_df[fcol].values\n",
    "    X_live = 1 - ((maxs - X_live) / rng)\n",
    "    prep_time += time.time() - t\n",
    "    \n",
    "    t = time.time()\n",
    "    lp = (gbm_1.predict(X_live) + gbm_2.predict(X_live))/2\n",
    "    prediction_time += time.time() -t\n",
    "    \n",
    "    t = time.time()\n",
    "    \n",
    "    confidence = lp\n",
    "    confidence = (confidence-confidence.min())/(confidence.max()-confidence.min())\n",
    "    confidence = confidence * 2 - 1\n",
    "    \n",
    "    preds = pd.DataFrame({'assetCode':market_obs_df['assetCode'],'confidence':confidence})\n",
    "    predictions_template_df = predictions_template_df.merge(preds,how='left').drop('confidenceValue',axis=1).fillna(0).rename(columns={'confidence':'confidenceValue'})\n",
    "    env.predict(predictions_template_df)\n",
    "    packaging_time += time.time() - t\n",
    "    \n",
    "env.write_submission_file()\n",
    "sub  = pd.read_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f189e556fd74e791c965476b07354fadc0ec1d7c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5b5c80a63310bb9f370a10cda02e0b4d01d18b36"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a6bd9fc9a59db29e02c8d0ad5f85cf7d0e7ab01b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3b5ffaaf52e8c84861c3ef9f94f30791f7c4cbf8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
